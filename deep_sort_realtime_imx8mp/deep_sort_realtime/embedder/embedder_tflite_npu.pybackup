import os
import cv2
import numpy as np
import tflite_runtime.interpreter as tflite

VX_DELEGATE_PATH="/nix/store/96bsy96b042wsqgzazpdhcdkqhai9k7n-vx-delegate-aarch64-unknown-linux-gnu-v-tf2.14.0/lib/libvx_delegate.so"

class TFLiteNPU_Embedder:
    """Custom TFLite embedder with NPU acceleration for deep-sort-realtime"""
    
    def __init__(self, model_path, use_npu=True, bgr=True, max_batch_size=16):
        self.model_path = model_path
        self.bgr = bgr
        self.max_batch_size = max_batch_size
        
        print(f"Loading TFLite MobileNet: {os.path.basename(model_path)}")
        
        # Create TFLite interpreter with VX delegate for NPU
        if use_npu and os.path.exists(VX_DELEGATE_PATH):
            try:
                self.interpreter = tflite.Interpreter(
                    model_path=model_path,
                    experimental_delegates=[
                        tflite.load_delegate(VX_DELEGATE_PATH)
                    ]
                )
                self.using_npu = True
                print("âœ… TFLite MobileNet NPU acceleration enabled")
            except Exception as e:
                print(f"âš  TFLite MobileNet NPU failed, using CPU: {e}")
                self.interpreter = tflite.Interpreter(model_path=model_path)
                self.using_npu = False
        else:
            self.interpreter = tflite.Interpreter(model_path=model_path)
            self.using_npu = False
        
        self.interpreter.allocate_tensors()
        
        # Get model details
        self.input_details = self.interpreter.get_input_details()
        self.output_details = self.interpreter.get_output_details()
        
        input_shape = self.input_details[0]['shape']
        self.input_size = (input_shape[2], input_shape[1])  # (width, height)
        print(f"TFLite MobileNet input size: {self.input_size}")
        
        # Warmup
        self._warmup()

    def _warmup(self):
        """Warmup the model"""
        dummy_input = np.random.randint(0, 255, self.input_details[0]['shape'], dtype=np.uint8)
        self.interpreter.set_tensor(self.input_details[0]['index'], dummy_input)
        self.interpreter.invoke()

    def predict(self, np_imgs):
        """
        Predict embeddings for batch of images.
        Compatible with deep-sort-realtime interface.
        
        Args:
            np_imgs: List or numpy array of images (crops)
        
        Returns:
            numpy array of feature embeddings
        """
        if len(np_imgs) == 0:
            return np.array([])
        
        # Handle single image
        if isinstance(np_imgs, np.ndarray) and len(np_imgs.shape) == 3:
            np_imgs = [np_imgs]
        
        embeddings = []
        
        # Process images in batches
        for i in range(0, len(np_imgs), self.max_batch_size):
            batch = np_imgs[i:i + self.max_batch_size]
            batch_embeddings = self._process_batch(batch)
            embeddings.extend(batch_embeddings)
        
        return np.array(embeddings)

    def _process_batch(self, batch_imgs):
        """Process a batch of images"""
        batch_embeddings = []
        
        for img in batch_imgs:
            # Convert BGR to RGB if needed
            if self.bgr:
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            
            # Resize to model input size
            resized = cv2.resize(img, self.input_size)
            
            # Preprocess based on model requirements
            if self.input_details[0]['dtype'] == np.uint8:
                input_data = np.expand_dims(resized, axis=0).astype(np.uint8)
            else:
                input_data = np.expand_dims(resized, axis=0).astype(np.float32) / 255.0
            
            # Run inference
            self.interpreter.set_tensor(self.input_details[0]['index'], input_data)
            self.interpreter.invoke()
            
            # Get feature vector (from last layer before classification)
            features = self.interpreter.get_tensor(self.output_details[-1]['index'])
            features_flat = features.flatten()
            
            # Normalize features
            norm = np.linalg.norm(features_flat)
            if norm > 0:
                features_flat = features_flat / norm
            
            batch_embeddings.append(features_flat)
        
        return batch_embeddings
